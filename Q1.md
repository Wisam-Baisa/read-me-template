Big O notation is a mathematical concept used in computer science to describe an algorithm’s efficiency in terms of time and space complexity. It provides a way to analyze how the runtime or memory requirements of an algorithm grow as the input size increases.  

#### *Big O Complexity Classes with Examples*  

- *O(1) - Constant Time*  
  The execution time does not depend on the input size.  
  Example: Accessing an array element by index.  
  java
  int getFirstElement(int[] arr) {
      return arr[0]; // Always takes constant time
  }
  
  
- *O(log n) - Logarithmic Time*  
  The execution time grows logarithmically as the input size increases.  
  Example: Binary search in a sorted array.  
  java
  int binarySearch(int[] arr, int target) {
      int left = 0, right = arr.length - 1;
      while (left <= right) {
          int mid = left + (right - left) / 2;
          if (arr[mid] == target) return mid;
          else if (arr[mid] < target) left = mid + 1;
          else right = mid - 1;
      }
      return -1;
  }
  

- *O(n) - Linear Time*  
  The execution time increases proportionally with input size.  
  Example: Iterating through an array.  
  java
  void printArray(int[] arr) {
      for (int i : arr) {
          System.out.println(i);
      }
  }
  

- *O(n²) - Quadratic Time*  
  The execution time grows quadratically with input size.  
  Example: Nested loops for bubble sort.  
  java
  void bubbleSort(int[] arr) {
      for (int i = 0; i < arr.length - 1; i++) {
          for (int j = 0; j < arr.length - i - 1; j++) {
              if (arr[j] > arr[j + 1]) {
                  int temp = arr[j];
                  arr[j] = arr[j + 1];
                  arr[j + 1] = temp;
              }
          }
      }
  }
